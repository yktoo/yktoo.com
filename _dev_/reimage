#!/usr/bin/python3

import os
import logging
import random
import re
import shutil
import string
import sys
import urllib.request
import urllib.error
import yaml

import cloudinary.uploader

CONTENT_FILE_EXTENSION = '.md'
DOWNLOAD_DIR = '/home/dk/tmp/_reimage_images'
IMAGE_MAP_FILE = '/home/dk/tmp/_reimage_map.yml'
FAILED_IMAGES_FILE = '/home/dk/tmp/_reimage_failed_urls.txt'


class Scanner:
    """Extracts image URLs from content files."""

    def __init__(self, path: str):
        self.path = path
        self.image_urls = set()

    def scan(self):
        """Recursively scan all directories starting at the scanner's path."""
        num_files = 0
        logging.info('Scanning %s...', self.path)
        for dir_path, dirs, files in os.walk(self.path):
            for file in files:
                if file.endswith(CONTENT_FILE_EXTENSION):
                    self._scan_file(os.path.join(dir_path, file))
                    num_files += 1

        # Done
        logging.info(
            'Scanning complete. %d files scanned, %d unique URLs have been discovered.',
            num_files,
            len(self.image_urls))

    def _scan_file(self, file_path):
        """Scan the provided file."""
        logging.debug('Processing %s', file_path)
        with open(file_path) as file:
            for line in file:
                for match in re.findall(r'http(?:s?)://\S*\b(?:blogspot|googleusercontent)\b[^"\s]+', line):
                    logging.debug('>>>> Match: "%s"', match)
                    self.image_urls.add(match)


class Downloader:
    """Downloads the provided image URLs."""

    def __init__(self, urls: set):
        self.urls = urls
        self.url_map = {}
        self.failed_urls = {}

    def download(self):
        """Download all image URLs into the target directory, and write out a map YAML file."""
        logging.info('Downloading %d URLs...', len(self.urls))

        # Make sure the target directory exists and is empty
        shutil.rmtree(DOWNLOAD_DIR)
        os.makedirs(DOWNLOAD_DIR)

        # Iterate all URLs
        count_ok = 0
        count_err = 0
        size = 0
        for url in self.urls:
            # Generate a new ID
            id = '{}{:04}'.format(''.join(random.choices(string.ascii_lowercase + string.digits, k=12)), count_ok)

            # Determine target name
            id += os.path.splitext(url)[1]

            # Download the file
            logging.debug('Downloading %s => %s', url, id)
            data = None
            reason = ''
            try:
                response = urllib.request.urlopen(url)
                data = response.read()
            except urllib.error.HTTPError as e:
                reason = 'HTTP error {}'.format(e.code)
            except urllib.error.URLError as e:
                reason = 'URL error: {}'.format(
                    e.reason if hasattr(e, 'reason') else e.code if hasattr(e, 'code') else '')

            # If failed
            if data is None:
                logging.warning('Failed to download %s: %s', url, reason)
                self.failed_urls[url] = reason
                count_err += 1

            # Save the data into a file otherwise
            else:
                file_path = os.path.join(DOWNLOAD_DIR, id)
                with open(file_path, 'wb') as file:
                    file.write(data)
                logging.debug('Saved %d bytes to %s', len(data), file_path)
                self.url_map[url] = id

                count_ok += 1
                size += len(data)

        # Export the map
        with open(IMAGE_MAP_FILE, 'w') as file:
            file.write('map:\n')
            file.writelines(['    "{}": {}\n'.format(url, id) for url, id in self.url_map.items()])

        # Export failed URLs
        with open(FAILED_IMAGES_FILE, 'w') as file:
            file.writelines(['{}\t{}\n'.format(url, reason) for url, reason in self.failed_urls.items()])

        # Done
        logging.info("Done downloading. %d images downloaded, %d URLs failed, %d bytes", count_ok, count_err, size)


class Uploader:
    """Uploads the provided image URLs to Cloudinary."""

    def __init__(self):
        # Validate the environment
        if 'CLOUDINARY_URL' not in os.environ:
            raise EnvironmentError('CLOUDINARY_URL is not set')

        # Read in the URL map
        with open(IMAGE_MAP_FILE) as file:
            self.url_map = yaml.safe_load(file)['map']
        logging.info('Loaded %d URL map entries from file', len(self.url_map))

    def upload(self):
        pass
        # TODO


# Main routine
if __name__ == '__main__':

    # Setup logging
    logging.basicConfig(level=logging.DEBUG if '-v' in sys.argv else logging.INFO, format='%(levelname)-8s %(message)s')

    # Root of the project
    root_dir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))
    logging.info('Project root: %s', root_dir)

    # If we need to download
    if '-d' in sys.argv:
        # Run the scanner
        scanner = Scanner(os.path.join(root_dir, 'content'))
        scanner.scan()

        # Run the downloader
        downloader = Downloader(scanner.image_urls)
        downloader.download()

    # If we need to upload
    if '-u' in sys.argv:
        uploader = Uploader()
        uploader.upload()
